{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5el_8SqFqVAT"
   },
   "source": [
    "\n",
    "In this notebook, You will do amazon review classification with BERT.[Download data from [this](https://www.kaggle.com/snap/amazon-fine-food-reviews/data) link]\n",
    "<pre> \n",
    "It contains 5 parts as below.  Detailed instrctions are given in the each cell. please read every comment we have written. \n",
    "    1. Preprocessing \n",
    "    2. Creating a BERT model from the Tensorflow HUB.\n",
    "    3. Tokenization\n",
    "    4. getting the pretrained embedding Vector for a given review from the BERT.\n",
    "    5. Using the embedding data apply NN and classify the reviews.\n",
    "    6. Creating a Data pipeline for BERT Model. \n",
    "\n",
    "<font size=5>instructions:</font>\n",
    "\n",
    "    1. Don't change any Grader Functions. Don't manipulate any Grader functions. \n",
    "    If you manipulate any, it will be considered as plagiarised. \n",
    "    \n",
    "    2. Please read the instructions on the code cells and markdown cells. We will explain what to write. \n",
    "    \n",
    "    3. please return outputs in the same format what we asked. Eg. Don't return List if we are asking for a numpy array.\n",
    "    \n",
    "    4. Please read the external links that we are given so that you will learn the concept behind the code that you are writing.\n",
    "    \n",
    "    5. We are giving instructions at each section if necessary, please follow them. \n",
    "\n",
    "<font size=5>Every Grader function has to return True. </font>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6JSKPjKwOLP"
   },
   "outputs": [],
   "source": [
    "#in this assignment you need two files reviews.csv and tokenization file\n",
    "#you can use gdown module to import both the files in colab from Google drive\n",
    "#the syntax is for gdown is !gdown --id file_id\n",
    "#please run the below cell to import the required files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUGbEZafwwzX",
    "outputId": "48698f3f-bbe0-42ee-91c4-dc575c60f5ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  category=FutureWarning,\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1GsD8JlAc_0yJ-1151LNr6rLw83RRUPgt\n",
      "To: /content/Reviews.csv\n",
      "100% 301M/301M [00:03<00:00, 85.8MB/s]\n",
      "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  category=FutureWarning,\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=13exfXiyiByluh1PfYK1EyZyizqxeCVG9\n",
      "To: /content/tokenization.py\n",
      "100% 17.3k/17.3k [00:00<00:00, 27.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1GsD8JlAc_0yJ-1151LNr6rLw83RRUPgt\n",
    "!gdown --id 13exfXiyiByluh1PfYK1EyZyizqxeCVG9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wOtG4cf0qVAZ"
   },
   "outputs": [],
   "source": [
    "#all imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "OcmiHdAJqVAi",
    "outputId": "66bf750c-153f-46b1-bbf0-ead5c58f983c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBsay58AqVAo"
   },
   "source": [
    "<font size=4>Grader function 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTBvOKFeqVAq",
    "outputId": "30538762-eca2-4431-9fcc-92a7bf5d7a88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_tf_version():\n",
    "    assert((tf.__version__)>'2')\n",
    "    return True\n",
    "grader_tf_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTWRqbrBqVAu"
   },
   "source": [
    "<pre><font size=6>Part-1: Preprocessing</font></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3csZKDrqVAv",
    "outputId": "e0f83837-1937-43a3-e8a6-0a1428e21d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568438 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Read the dataset - Amazon fine food reviews\n",
    "reviews = pd.read_csv(r\"Reviews.csv\")\n",
    "#check the info of the dataset\n",
    "reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xokNn7qZqVAz",
    "outputId": "c4860bc8-e77d-4415-cc00-3c7f5319387d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d415df28-a86d-4105-9b1c-37b358959ddb\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d415df28-a86d-4105-9b1c-37b358959ddb')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d415df28-a86d-4105-9b1c-37b358959ddb button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d415df28-a86d-4105-9b1c-37b358959ddb');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  I have bought several of the Vitality canned d...      5\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      1\n",
       "2  This is a confection that has been around a fe...      4\n",
       "3  If you are looking for the secret ingredient i...      2\n",
       "4  Great taffy at a great price.  There was a wid...      5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get only 2 columns - Text, Score\n",
    "#drop the NAN values\n",
    "reviews = reviews[['Text','Score']]\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xu2IyAfKqUmS"
   },
   "source": [
    "Checking for null values - As can be observed from the below code there are no null values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04kqGxz8qNFh",
    "outputId": "bb7c9d03-7076-4f33-a0c5-627764c0ee41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text     0\n",
       "Score    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.isnull().apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "5GZt7pVkqVA4",
    "outputId": "e2911544-ef73-4933-8623-288a139a061c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ab10a2be-6724-43a7-8196-6ff04120edb1\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab10a2be-6724-43a7-8196-6ff04120edb1')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ab10a2be-6724-43a7-8196-6ff04120edb1 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ab10a2be-6724-43a7-8196-6ff04120edb1');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  I have bought several of the Vitality canned d...    1.0\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...    0.0\n",
       "2  This is a confection that has been around a fe...    1.0\n",
       "3  If you are looking for the secret ingredient i...    0.0\n",
       "4  Great taffy at a great price.  There was a wid...    1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if score> 3, set score = 1\n",
    "#if score<=2, set score = 0\n",
    "#if score == 3, remove the rows.\n",
    "\n",
    "def binary_conversion(x):\n",
    "  if x > 3:\n",
    "    return 1\n",
    "  elif x<=2:\n",
    "    return 0\n",
    "  return None\n",
    "\n",
    "reviews['Score'] = reviews['Score'].apply(binary_conversion)\n",
    "reviews.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHpAV3DorNsq",
    "outputId": "509349c7-f6d6-4a6f-d86e-11091ed945d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42640"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(reviews.Score.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Buz7Fo7Crv6Y",
    "outputId": "ee3c6abc-7b78-4d7a-f001-14f2c851566e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525814, 2)\n"
     ]
    }
   ],
   "source": [
    "reviews.dropna(inplace = True)\n",
    "print(reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVe8LlkrqVA6"
   },
   "source": [
    "<font size=4>Grader function 2 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7mDXSiJpqVA7",
    "outputId": "7a892679-8149-4c17-978c-799da95b5e86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_reviews():\n",
    "    temp_shape = (reviews.shape == (525814, 2)) and (reviews.Score.value_counts()[1]==443777)\n",
    "    assert(temp_shape == True)\n",
    "    return True\n",
    "grader_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xYZ-UB9UqVA-"
   },
   "outputs": [],
   "source": [
    "def get_wordlen(x):\n",
    "    return len(x.split())\n",
    "reviews['len'] = reviews.Text.apply(get_wordlen)\n",
    "reviews = reviews[reviews.len<50]\n",
    "reviews = reviews.sample(n=100000, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CvldQriGqVBB"
   },
   "outputs": [],
   "source": [
    "#remove HTML from the Text column and save in the Text column only\n",
    "import re\n",
    "def remove_html(x):\n",
    "  return re.sub(\"<.*?>\", '', x)\n",
    "\n",
    "reviews['Text'] = reviews['Text'].apply(remove_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AhfN1s2mqVBD",
    "outputId": "ac1aa85e-649a-4e3c-dd50-d6d16d49aa57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Text  Score  len\n",
      "64117   The tea was of great quality and it tasted lik...    1.0   30\n",
      "418112  My cat loves this.  The pellets are nice and s...    1.0   31\n",
      "357829  Great product. Does not completely get rid of ...    1.0   41\n",
      "175872  This gum is my favorite!  I would advise every...    1.0   27\n",
      "178716  I also found out about this product because of...    1.0   22\n"
     ]
    }
   ],
   "source": [
    "#print head 5\n",
    "print(reviews.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "NsYDd3okqVBF"
   },
   "outputs": [],
   "source": [
    "#split the data into train and test data(20%) with Stratify sampling, random state 33\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews['Text'], reviews['Score'], test_size = 0.2, stratify = reviews['Score'], \n",
    "                                                    random_state = 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ITFGM2KZvDRX"
   },
   "outputs": [],
   "source": [
    "vals_tr = y_train.value_counts()\n",
    "vals_te = y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "-Q6OAcrOqVBI",
    "outputId": "129c2d3d-fdb3-448d-cd0b-677bfb2d80b7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot bar graphs of y_train and y_test\n",
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(8)\n",
    "fig.suptitle('Comparing Ratio of Classes in Train and Test')\n",
    "ax1.bar(vals_tr.index, vals_tr.values, color = ['green', 'orange'])\n",
    "ax1.set_title(\"y_train\")\n",
    "ax1.set_xticks([0, 1])\n",
    "ax2.bar(vals_te.index, vals_te.values, color = ['green', 'orange'])\n",
    "ax2.set_title(\"y_test\")\n",
    "ax2.set_xticks([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Up-z5boWqVBK"
   },
   "outputs": [],
   "source": [
    "#saving to disk. if we need, we can load preprocessed data directly. \n",
    "reviews.to_csv('preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBtqNGN9qVBM"
   },
   "source": [
    "<pre><font size=6>Part-2: Creating BERT Model</font> \n",
    "\n",
    "If you want to know more about BERT, You can watch live sessions on Transformers and BERt. \n",
    "we will strongly recommend you to read <a href=\"https://jalammar.github.io/illustrated-transformer/\">Transformers</a>, <a href=\"https://arxiv.org/abs/1810.04805\">BERT Paper</a> and, <a href=\"https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\">This blog</a>.\n",
    "\n",
    "\n",
    "For this assignment, we are using <a href=\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\">BERT uncased Base model</a>. \n",
    "It uses L=12 hidden layers (i.e., Transformer blocks), a hidden size of H=768, and A=12 attention heads. </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "i8xd2HejqVBN"
   },
   "outputs": [],
   "source": [
    "## Loading the Pretrained Model from tensorflow HUB\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# maximum length of a seq in the data we have, for now i am making it as 55. You can change this\n",
    "max_seq_length = 55\n",
    "\n",
    "#BERT takes 3 inputs\n",
    "\n",
    "#this is input words. Sequence of words represented as integers\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "\n",
    "#mask vector if you are padding anything\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "\n",
    "#segment vectors. If you are giving only one sentence for the classification, total seg vector is 0. \n",
    "#If you are giving two sentenced with [sep] token separated, first seq segment vectors are zeros and \n",
    "#second seq segment vector are 1's\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "#bert layer \n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "#Bert model\n",
    "#We are using only pooled output not sequence out. \n",
    "#If you want to know about those, please read https://www.kaggle.com/questions-and-answers/86510\n",
    "bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQJsjg6fqVBQ",
    "outputId": "335309fe-eb14-45c9-924f-6bffda83c956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer)    [(None, 55)]         0           []                               \n",
      "                                                                                                  \n",
      " input_mask (InputLayer)        [(None, 55)]         0           []                               \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)       [(None, 55)]         0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
      "                                 (None, 55, 768)]                 'input_mask[0][0]',             \n",
      "                                                                  'segment_ids[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,482,241\n",
      "Trainable params: 0\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3z0OMA5qVBS",
    "outputId": "4ae08392-312f-4df6-db44-b61b2a64d1b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ewv4hFCsqVBU"
   },
   "source": [
    "<pre><font size=6>Part-3: Tokenization</font></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "tX3VEFjiqVBU"
   },
   "outputs": [],
   "source": [
    "#getting Vocab file\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OOHlaNe_3bB2",
    "outputId": "8db75e97-973b-4d68-d735-52889704ba57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 14.3 MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "Y_iPwa99qVBW"
   },
   "outputs": [],
   "source": [
    "import tokenization #We have given tokenization.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "guJMLJ8bqVBY"
   },
   "outputs": [],
   "source": [
    "# Create tokenizer \" Instantiate FullTokenizer\" \n",
    "# name must be \"tokenizer\"\n",
    "# the FullTokenizer takes two parameters 1. vocab_file and 2. do_lower_case \n",
    "# we have created these in the above cell ex: FullTokenizer(vocab_file, do_lower_case )\n",
    "# please check the \"tokenization.py\" file the complete implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "qlGFtp2xxzt6"
   },
   "outputs": [],
   "source": [
    "# if you are getting error for sentencepiece module you can install it using below command while running this cell for the first time\n",
    "#!pip install sentencepiece\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file,do_lower_case )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKkGLhR-qVBd"
   },
   "source": [
    "<font size=4>Grader function 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2CPu850xqVBe",
    "outputId": "790615f0-205d-41c9-e2ef-b4e307aeffeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it has to give no error \n",
    "def grader_tokenize(tokenizer):\n",
    "    out = False\n",
    "    try:\n",
    "        out=('[CLS]' in tokenizer.vocab) and ('[SEP]' in tokenizer.vocab)\n",
    "    except:\n",
    "        out = False\n",
    "    assert(out==True)\n",
    "    return out\n",
    "grader_tokenize(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9crhPylQqVBg"
   },
   "outputs": [],
   "source": [
    "# Create train and test tokens (X_train_tokens, X_test_tokens) from (X_train, X_test) using Tokenizer and \n",
    "\n",
    "# add '[CLS]' at start of the Tokens and '[SEP]' at the end of the tokens. \n",
    "\n",
    "# maximum number of tokens is 55(We already given this to BERT layer above) so shape is (None, 55)\n",
    "\n",
    "# if it is less than 55, add '[PAD]' token else truncate the tokens length.(similar to padding)\n",
    "\n",
    "# Based on padding, create the mask for Train and Test ( 1 for real token, 0 for '[PAD]'), \n",
    "# it will also same shape as input tokens (None, 55) save those in X_train_mask, X_test_mask\n",
    "\n",
    "# Create a segment input for train and test. We are using only one sentence so all zeros. This shape will also (None, 55)\n",
    "\n",
    "# type of all the above arrays should be numpy arrays\n",
    "\n",
    "# after execution of this cell, you have to get \n",
    "# X_train_tokens, X_train_mask, X_train_segment\n",
    "# X_test_tokens, X_test_mask, X_test_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMoHhFvSAuM-",
    "outputId": "14b91fa5-1d70-4f39-aee5-939965e4cabc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "KkmHbM9H4crz"
   },
   "outputs": [],
   "source": [
    "train_tokens = []\n",
    "train_mask = []\n",
    "train_segment = []\n",
    "for text in X_train.values:\n",
    "  tokens = tokenizer.tokenize(text)\n",
    "  if len(tokens) > (max_seq_length-2):\n",
    "    tokens = tokens[0:(max_seq_length-2)]\n",
    "  tokens = ['[CLS]', *tokens, '[SEP]']\n",
    "  token_length = len(tokens)\n",
    "  if len(tokens) < max_seq_length:\n",
    "    pad = [\"[PAD]\"]\n",
    "    tokens.extend(pad*(max_seq_length - len(tokens)))\n",
    "  tokens = np.array(tokens)\n",
    "  mask = np.array([1]*token_length+ [0]*(max_seq_length - token_length))\n",
    "  segment = np.array([0]*max_seq_length)\n",
    "  train_tokens.append(np.array(tokenizer.convert_tokens_to_ids(tokens)))\n",
    "  train_mask.append(mask)\n",
    "  train_segment.append(segment)\n",
    "\n",
    "X_train_tokens = np.array(train_tokens)\n",
    "X_train_mask = np.array(train_mask)\n",
    "X_train_segment = np.array(train_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "nGwbHZRK6wrM"
   },
   "outputs": [],
   "source": [
    "test_tokens = []\n",
    "test_mask = []\n",
    "test_segment = []\n",
    "for text in X_test.values:\n",
    "  tokens = tokenizer.tokenize(text)\n",
    "  if len(tokens) > (max_seq_length-2):\n",
    "    tokens = tokens[0:(max_seq_length-2)]\n",
    "  tokens = ['[CLS]', *tokens, '[SEP]']\n",
    "  token_length = len(tokens)\n",
    "  if len(tokens) < max_seq_length:\n",
    "    pad = [\"[PAD]\"]\n",
    "    tokens.extend(pad*(max_seq_length - len(tokens)))\n",
    "  tokens = np.array(tokens)\n",
    "  mask = np.array([1]*token_length+ [0]*(max_seq_length - token_length))\n",
    "  segment = np.array([0]*max_seq_length)\n",
    "  test_tokens.append(np.array(tokenizer.convert_tokens_to_ids(tokens)))\n",
    "  test_mask.append(mask)\n",
    "  test_segment.append(segment)\n",
    "\n",
    "X_test_tokens = np.array(test_tokens)\n",
    "X_test_mask = np.array(test_mask)\n",
    "X_test_segment = np.array(test_segment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kv1-t4OjqVBj"
   },
   "source": [
    "#### Example\n",
    "<img src='https://i.imgur.com/5AhhmgU.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "dxhggBxwqVBj"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "xF0idMRDqVBm"
   },
   "outputs": [],
   "source": [
    "##save all your results to disk so that, no need to run all again. \n",
    "pickle.dump((X_train, X_train_tokens, X_train_mask, X_train_segment, y_train),open('train_data.pkl','wb'))\n",
    "pickle.dump((X_test, X_test_tokens, X_test_mask, X_test_segment, y_test),open('test_data.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Leu1URGzqVBo"
   },
   "outputs": [],
   "source": [
    "#you can load from disk\n",
    "#X_train, X_train_tokens, X_train_mask, X_train_segment, y_train = pickle.load(open(\"train_data.pkl\", 'rb')) \n",
    "#X_test, X_test_tokens, X_test_mask, X_test_segment, y_test = pickle.load(open(\"test_data.pkl\", 'rb')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjPv8VkJqVBr"
   },
   "source": [
    "<font size=4>Grader function 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qekHJgmdqVBs",
    "outputId": "f06b95c5-e7c2-4b83-a2ee-743c5aec7323"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_alltokens_train():\n",
    "    out = False\n",
    "    \n",
    "    if type(X_train_tokens) == np.ndarray:\n",
    "        \n",
    "        temp_shapes = (X_train_tokens.shape[1]==max_seq_length) and (X_train_mask.shape[1]==max_seq_length) and \\\n",
    "        (X_train_segment.shape[1]==max_seq_length)\n",
    "        \n",
    "        segment_temp = not np.any(X_train_segment)\n",
    "        \n",
    "        mask_temp = np.sum(X_train_mask==0) == np.sum(X_train_tokens==0)\n",
    "        \n",
    "        no_cls = np.sum(X_train_tokens==tokenizer.vocab['[CLS]'])==X_train_tokens.shape[0]\n",
    "        \n",
    "        no_sep = np.sum(X_train_tokens==tokenizer.vocab['[SEP]'])==X_train_tokens.shape[0]\n",
    "        \n",
    "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
    "      \n",
    "    else:\n",
    "        print('Type of all above token arrays should be numpy array not list')\n",
    "        out = False\n",
    "    assert(out==True)\n",
    "    return out\n",
    "\n",
    "grader_alltokens_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnvC6X_wqVBu"
   },
   "source": [
    "<font size=4>Grader function 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Av4SRMPSqVBv",
    "outputId": "3f6cd5da-606a-4cc8-f47a-6ea5bd3f5e5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_alltokens_test():\n",
    "    out = False\n",
    "    if type(X_test_tokens) == np.ndarray:\n",
    "        \n",
    "        temp_shapes = (X_test_tokens.shape[1]==max_seq_length) and (X_test_mask.shape[1]==max_seq_length) and \\\n",
    "        (X_test_segment.shape[1]==max_seq_length)\n",
    "        \n",
    "        segment_temp = not np.any(X_test_segment)\n",
    "        \n",
    "        mask_temp = np.sum(X_test_mask==0) == np.sum(X_test_tokens==0)\n",
    "        \n",
    "        no_cls = np.sum(X_test_tokens==tokenizer.vocab['[CLS]'])==X_test_tokens.shape[0]\n",
    "        \n",
    "        no_sep = np.sum(X_test_tokens==tokenizer.vocab['[SEP]'])==X_test_tokens.shape[0]\n",
    "        \n",
    "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
    "      \n",
    "    else:\n",
    "        print('Type of all above token arrays should be numpy array not list')\n",
    "        out = False\n",
    "    assert(out==True)\n",
    "    return out\n",
    "grader_alltokens_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEj-Eua5qVBx"
   },
   "source": [
    "<pre><font size=6>Part-4: Getting Embeddings from BERT Model</font>\n",
    "We already created the BERT model in the part-2 and input data in the part-3. \n",
    "We will utlize those two and will get the embeddings for each sentence in the \n",
    "Train and test data.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwOVgQFDqVBy",
    "outputId": "0eabfbf2-0895-46b2-bb33-e38cef7b3c77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_word_ids')>,\n",
       " <KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_mask')>,\n",
       " <KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'segment_ids')>]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcpkQq1OqVB0",
    "outputId": "10da9b6e-da98-4cf2-d5d1-fd0efad0dc0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "IxdIlOIBlm7j"
   },
   "outputs": [],
   "source": [
    "# get the train output, BERT model will give one output so save in\n",
    "# X_train_pooled_output\n",
    "#this cell will take some time to execute, make sure thay you have stable internet connection\n",
    "X_train_pooled_output = bert_model.predict([X_train_tokens,X_train_mask,X_train_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "yZT11BCol4gL"
   },
   "outputs": [],
   "source": [
    "# get the test output, BERT model will give one output so save in\n",
    "# X_test_pooled_output\n",
    "X_test_pooled_output = bert_model.predict([X_test_tokens,X_test_mask,X_test_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "DL6JVojfqVB8"
   },
   "outputs": [],
   "source": [
    "##save all your results to disk so that, no need to run all again. \n",
    "pickle.dump((X_train_pooled_output, X_test_pooled_output),open('final_output.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSQcBdROqVB9"
   },
   "outputs": [],
   "source": [
    "#X_train_pooled_output, X_test_pooled_output= pickle.load(open('final_output.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulEXFE7aqVCA"
   },
   "source": [
    "<font size=4>Grader function 6 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHCsW0IvqVCB",
    "outputId": "3c0c32dc-198e-4086-9ca2-f7dec5002e80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we have X_train_pooled_output, y_train\n",
    "#X_test_pooled_ouput, y_test\n",
    "\n",
    "#please use this grader to evaluate\n",
    "def greader_output():\n",
    "    assert(X_train_pooled_output.shape[1]==768)\n",
    "    assert(len(y_train)==len(X_train_pooled_output))\n",
    "    assert(X_test_pooled_output.shape[1]==768)\n",
    "    assert(len(y_test)==len(X_test_pooled_output))\n",
    "    assert(len(y_train.shape)==1)\n",
    "    assert(len(X_train_pooled_output.shape)==2)\n",
    "    assert(len(y_test.shape)==1)\n",
    "    assert(len(X_test_pooled_output.shape)==2)\n",
    "    return True\n",
    "greader_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYwS1QbAqVCD"
   },
   "source": [
    "<pre><font size=6>Part-5: Training a NN with 768 features</font>\n",
    "\n",
    "Create a NN and train the NN. \n",
    "1.<b> You have to use AUC as metric. Do not use tf.keras.metrics.AUC</b> \n",
    "<b> You have to write custom code for AUC and print it at the end of each epoch</b> \n",
    "2. You can use any architecture you want. \n",
    "3. You have to use tensorboard to log all your metrics and Losses. You have to send those logs. \n",
    "4. Print the loss and metric at every epoch. \n",
    "5. You have to submit without overfitting and underfitting. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "od8PQlYRqVCE"
   },
   "outputs": [],
   "source": [
    "##imports\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LSTM, Flatten\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "SPMqYKYyN0vv"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def auc( y_true, y_pred ) :\n",
    "    score = tf.py_function( lambda y_true, y_pred : roc_auc_score( y_true, y_pred, average='macro', sample_weight=None).astype('float32'),\n",
    "                        [y_true, y_pred],\n",
    "                        'float32',\n",
    "                       name='sklearnAUC' )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oZDP9v6NOSoY",
    "outputId": "28e72866-4a88-4bc0-ac30-0a704c1bb271"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 768)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JekT-omPUQk7",
    "outputId": "ed89c65b-7743-4cc5-9cba-c158b717cf72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 768)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FRlnehICTxXh",
    "outputId": "fdba42a3-505d-4f32-e05c-640746bd5bf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 768, 1)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = X_train_pooled_output.reshape(80000, 768, 1)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "0_wspPwPULys"
   },
   "outputs": [],
   "source": [
    "w = X_test_pooled_output.reshape(20000, 768, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DSnmX3WnqVCG",
    "outputId": "92351296-8352-4dc5-b778-19aaf3827170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 768, 64)\n",
      "(None, 49152)\n",
      "(None, 32)\n",
      "(None, 49152)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 768, 1)]          0         \n",
      "                                                                 \n",
      " cu_dnnlstm (CuDNNLSTM)      (None, 768, 64)           17152     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 49152)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 49152)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 98306     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,458\n",
      "Trainable params: 115,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "##create an Neural Network and train your model on X_train_pooled_output and y_train\n",
    "# you can start as follows\n",
    "input_layer = Input(shape = (X_train_pooled_output.shape[1],1))\n",
    "lstm_layer = CuDNNLSTM(64, return_sequences = True)(input_layer)\n",
    "print(lstm_layer.get_shape())\n",
    "flat1 = Flatten()(lstm_layer)\n",
    "print(flat1.get_shape())\n",
    "dense = Dense(32,activation = 'relu', kernel_initializer = HeNormal(), kernel_regularizer = L2(0.0001))(flat1)\n",
    "print(dense.get_shape())\n",
    "dropout = Dropout(0.5)(flat1)\n",
    "print(dropout.get_shape())\n",
    "output = Dense(2, activation = 'softmax')(dropout)\n",
    "model = Model(input_layer, output)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.0006), metrics = [auc])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "Vm9kI7XoUErY",
    "outputId": "c84e5b98-3f52-4324-c4d4-72126ab179f6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model, to_file='model.png', show_shapes=False, show_layer_names=True, \n",
    "    rankdir='TB', expand_nested=False, dpi=96\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "TV3jX9LpUmEv"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "_5v-EXuNWEt8"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "target_train = ohe.fit_transform(y_train.values.reshape(-1,1)).toarray()\n",
    "target_test = ohe.transform(y_test.values.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "A3qSehcLXLZB"
   },
   "outputs": [],
   "source": [
    "#to avoid the error: Creating variables on a non-first call to a function decorated with tf.function.\n",
    "#reference: https://stackoverflow.com/questions/58352326/running-the-tensorflow-2-0-code-gives-valueerror-tf-function-decorated-functio\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3est6u_sUpit",
    "outputId": "2d162898-e76b-442a-d685-5218aa1afce9"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1950 - auc: 0.9442"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_auc improved from -inf to 0.94731, saving model to weights_copy.best.hdf5\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1950 - auc: 0.9442 - val_loss: 0.1897 - val_auc: 0.9473\n",
      "Epoch 2/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1934 - auc: 0.9435\n",
      "Epoch 2: val_auc improved from 0.94731 to 0.94841, saving model to weights_copy.best.hdf5\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1934 - auc: 0.9435 - val_loss: 0.1859 - val_auc: 0.9484\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1943 - auc: 0.9445\n",
      "Epoch 3: val_auc did not improve from 0.94841\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1943 - auc: 0.9445 - val_loss: 0.1814 - val_auc: 0.9478\n",
      "Epoch 4/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1925 - auc: 0.9449\n",
      "Epoch 4: val_auc did not improve from 0.94841\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1926 - auc: 0.9449 - val_loss: 0.1940 - val_auc: 0.9478\n",
      "Epoch 5/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1935 - auc: 0.9448\n",
      "Epoch 5: val_auc improved from 0.94841 to 0.94870, saving model to weights_copy.best.hdf5\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1936 - auc: 0.9448 - val_loss: 0.1815 - val_auc: 0.9487\n",
      "Epoch 6/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1927 - auc: 0.9449\n",
      "Epoch 6: val_auc improved from 0.94870 to 0.94878, saving model to weights_copy.best.hdf5\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1927 - auc: 0.9449 - val_loss: 0.1793 - val_auc: 0.9488\n",
      "Epoch 7/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1911 - auc: 0.9456\n",
      "Epoch 7: val_auc improved from 0.94878 to 0.94905, saving model to weights_copy.best.hdf5\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1910 - auc: 0.9457 - val_loss: 0.1788 - val_auc: 0.9491\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1904 - auc: 0.9455\n",
      "Epoch 8: val_auc did not improve from 0.94905\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1904 - auc: 0.9455 - val_loss: 0.1809 - val_auc: 0.9487\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1906 - auc: 0.9455\n",
      "Epoch 9: val_auc improved from 0.94905 to 0.94975, saving model to weights_copy.best.hdf5\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1906 - auc: 0.9455 - val_loss: 0.1800 - val_auc: 0.9498\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1920 - auc: 0.9466\n",
      "Epoch 10: val_auc did not improve from 0.94975\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1920 - auc: 0.9466 - val_loss: 0.1804 - val_auc: 0.9495\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1883 - auc: 0.9471\n",
      "Epoch 11: val_auc did not improve from 0.94975\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1883 - auc: 0.9471 - val_loss: 0.1920 - val_auc: 0.9494\n",
      "Epoch 12/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1896 - auc: 0.9470\n",
      "Epoch 12: val_auc improved from 0.94975 to 0.95002, saving model to weights_copy.best.hdf5\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1896 - auc: 0.9470 - val_loss: 0.1774 - val_auc: 0.9500\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1886 - auc: 0.9476\n",
      "Epoch 13: val_auc did not improve from 0.95002\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1886 - auc: 0.9476 - val_loss: 0.1930 - val_auc: 0.9494\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1890 - auc: 0.9467\n",
      "Epoch 14: val_auc improved from 0.95002 to 0.95035, saving model to weights_copy.best.hdf5\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1890 - auc: 0.9467 - val_loss: 0.2236 - val_auc: 0.9504\n",
      "Epoch 15/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1890 - auc: 0.9477\n",
      "Epoch 15: val_auc did not improve from 0.95035\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1891 - auc: 0.9477 - val_loss: 0.1764 - val_auc: 0.9502\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1879 - auc: 0.9476\n",
      "Epoch 16: val_auc improved from 0.95035 to 0.95039, saving model to weights_copy.best.hdf5\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1879 - auc: 0.9476 - val_loss: 0.1831 - val_auc: 0.9504\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1880 - auc: 0.9472\n",
      "Epoch 17: val_auc improved from 0.95039 to 0.95051, saving model to weights_copy.best.hdf5\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1880 - auc: 0.9472 - val_loss: 0.1761 - val_auc: 0.9505\n",
      "Epoch 18/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1877 - auc: 0.9474\n",
      "Epoch 18: val_auc did not improve from 0.95051\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1877 - auc: 0.9474 - val_loss: 0.1857 - val_auc: 0.9498\n",
      "Epoch 19/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1898 - auc: 0.9472\n",
      "Epoch 19: val_auc did not improve from 0.95051\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1899 - auc: 0.9471 - val_loss: 0.1812 - val_auc: 0.9493\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1874 - auc: 0.9477\n",
      "Epoch 20: val_auc did not improve from 0.95051\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1874 - auc: 0.9477 - val_loss: 0.1786 - val_auc: 0.9504\n",
      "Epoch 21/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1883 - auc: 0.9474\n",
      "Epoch 21: val_auc did not improve from 0.95051\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1884 - auc: 0.9473 - val_loss: 0.1910 - val_auc: 0.9505\n",
      "Epoch 22/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1857 - auc: 0.9481\n",
      "Epoch 22: val_auc did not improve from 0.95051\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1857 - auc: 0.9481 - val_loss: 0.1769 - val_auc: 0.9505\n",
      "Epoch 23/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1867 - auc: 0.9481\n",
      "Epoch 23: val_auc improved from 0.95051 to 0.95092, saving model to weights_copy.best.hdf5\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1867 - auc: 0.9481 - val_loss: 0.1763 - val_auc: 0.9509\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1860 - auc: 0.9483\n",
      "Epoch 24: val_auc improved from 0.95092 to 0.95114, saving model to weights_copy.best.hdf5\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1860 - auc: 0.9483 - val_loss: 0.1749 - val_auc: 0.9511\n",
      "Epoch 25/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1865 - auc: 0.9481\n",
      "Epoch 25: val_auc improved from 0.95114 to 0.95120, saving model to weights_copy.best.hdf5\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1865 - auc: 0.9481 - val_loss: 0.1772 - val_auc: 0.9512\n",
      "Epoch 26/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1858 - auc: 0.9485\n",
      "Epoch 26: val_auc did not improve from 0.95120\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1858 - auc: 0.9485 - val_loss: 0.1782 - val_auc: 0.9509\n",
      "Epoch 27/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1847 - auc: 0.9491\n",
      "Epoch 27: val_auc did not improve from 0.95120\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1847 - auc: 0.9491 - val_loss: 0.1822 - val_auc: 0.9512\n",
      "Epoch 28/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1857 - auc: 0.9484\n",
      "Epoch 28: val_auc improved from 0.95120 to 0.95167, saving model to weights_copy.best.hdf5\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1857 - auc: 0.9484 - val_loss: 0.1809 - val_auc: 0.9517\n",
      "Epoch 29/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1859 - auc: 0.9488\n",
      "Epoch 29: val_auc did not improve from 0.95167\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1858 - auc: 0.9488 - val_loss: 0.1820 - val_auc: 0.9514\n",
      "Epoch 30/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1852 - auc: 0.9482\n",
      "Epoch 30: val_auc did not improve from 0.95167\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1852 - auc: 0.9483 - val_loss: 0.1754 - val_auc: 0.9510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f949c135350>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%load_ext tensorboard\n",
    "#import datetime, os\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights_copy.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only = True, mode='max')\n",
    "log_dir = os.path.join(\"logs\",'fits', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1)\n",
    "model.fit(x = v, y = target_train, validation_data = (w, target_test), epochs = 30, batch_size = 80,\n",
    "          callbacks = [checkpoint]) #, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TU-k_ezaBpG"
   },
   "source": [
    "Tried creating tensorboard graphs but got  - 'Function' object has no attribute '_concrete_stateful_fn'. I was unable to debug the error, I couldn't find any solution on the internet as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "W02m4g-Ckzwg"
   },
   "outputs": [],
   "source": [
    "model.save('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcILeYZI9pxm"
   },
   "source": [
    "<Pre><font size=6>Part-6: Creating a Data pipeline for BERT Model</font> \n",
    "1. Pipeline is a way to codify and automate the workflow.\n",
    "2. Download the test.csv file from here <a href=\"https://drive.google.com/file/d/1QwjqTsqTX2vdy7fTmeXjxP3dq8IAVLpo/view?usp=sharing\">here</a> </pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_74n3sgFjvlM"
   },
   "outputs": [],
   "source": [
    "#there is an alterante way to load files from Google drive directly to your Colab session\n",
    "# you can use gdown module to import the files as follows\n",
    "#for example for test.csv you can write your code as !gdown --id file_id (remove the # from next line and run it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kwv_BIV9xWt7",
    "outputId": "727d9a9b-fe20-4197-e728-9716c7566d78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  category=FutureWarning,\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1QwjqTsqTX2vdy7fTmeXjxP3dq8IAVLpo\n",
      "To: /content/test.csv\n",
      "100% 62.1k/62.1k [00:00<00:00, 66.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1QwjqTsqTX2vdy7fTmeXjxP3dq8IAVLpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "lQcoHbUKjgvF"
   },
   "outputs": [],
   "source": [
    "#read the csv file\n",
    "test_df = pd.read_csv('test.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "W1Pj4VNVmEab",
    "outputId": "04e12dac-ed4f-4943-cdaa-85635ae9fc77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2a1690a2-2f9b-416a-9b17-8bf6c225f139\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just opened Greenies Joint Care (individually ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This product rocks :) My mom was very happy w/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The product was fine, but the cost of shipping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love this soup. It's great as part of a meal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Getting ready to order again. These are great ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a1690a2-2f9b-416a-9b17-8bf6c225f139')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-2a1690a2-2f9b-416a-9b17-8bf6c225f139 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-2a1690a2-2f9b-416a-9b17-8bf6c225f139');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                Text\n",
       "0  Just opened Greenies Joint Care (individually ...\n",
       "1  This product rocks :) My mom was very happy w/...\n",
       "2  The product was fine, but the cost of shipping...\n",
       "3  I love this soup. It's great as part of a meal...\n",
       "4  Getting ready to order again. These are great ..."
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zii6hgejdhQ"
   },
   "source": [
    "<Pre>1. You have to write a function that takes the test_df,trained model and the required parameters as input. \n",
    "2. Perform all the preproceesing steps inside the function.\n",
    "- Remove all the html tags\n",
    "- Now do tokenization [Part 3 as mentioned above]\n",
    "- Create tokens,mask array and segment array\n",
    "- Get Embeddings from BERT Model [Part 4 as mentioned above] , let it be X_test\n",
    "- Print the shape of output(X_test.shape).You should get (352,768)\n",
    "3. Predit the output of X_test with the neural network model which we trained earlier.\n",
    "\n",
    "4. Return the occurences of class labels from the function.\n",
    "The output should be the count of datapoints classified as 1 or 0.\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "g9g6C_kgjcan"
   },
   "outputs": [],
   "source": [
    "def remove_html(x):\n",
    "  return re.sub(\"<.*?>\", '', x)\n",
    "\n",
    "def pipeline(X_test, filepath):\n",
    "  '''\n",
    "  Function takes test datapoints and the filepath where the weights of the optimal model are stored.\n",
    "  Returns the no. of datapoints belonging to each class as predictions of the test datapoints.\n",
    "  '''\n",
    "  \n",
    "  #removing html tags from the data\n",
    "  X_test['Text'] = X_test['Text'].apply(remove_html)\n",
    "\n",
    "  #creating tokens, mask and segment for test data\n",
    "  test_tokens = []\n",
    "  test_mask = []\n",
    "  test_segment = []\n",
    "  for text in X_test.values:\n",
    "    tokens = tokenizer.tokenize(text[0])\n",
    "    if len(tokens) > (max_seq_length-2):\n",
    "      tokens = tokens[0:(max_seq_length-2)]\n",
    "    tokens = ['[CLS]', *tokens, '[SEP]']\n",
    "    token_length = len(tokens)\n",
    "    if len(tokens) < max_seq_length:\n",
    "      pad = [\"[PAD]\"]\n",
    "      tokens.extend(pad*(max_seq_length - len(tokens)))\n",
    "    tokens = np.array(tokens)\n",
    "    mask = np.array([1]*token_length+ [0]*(max_seq_length - token_length))\n",
    "    segment = np.array([0]*max_seq_length)\n",
    "    test_tokens.append(np.array(tokenizer.convert_tokens_to_ids(tokens)))\n",
    "    test_mask.append(mask)\n",
    "    test_segment.append(segment)\n",
    "\n",
    "  X_test_tokens = np.array(test_tokens)\n",
    "  X_test_mask = np.array(test_mask)\n",
    "  X_test_segment = np.array(test_segment)\n",
    "\n",
    "  #getting BERT embeddings for test data\n",
    "  X_test_pooled = bert_model.predict([X_test_tokens,X_test_mask,X_test_segment])\n",
    "  \n",
    "  #printing the shape of the embeddings obtained\n",
    "  print(X_test_pooled.shape)\n",
    "\n",
    "  #reshaping X_test_pooled for CuDNNLSTM - as it needs 3dim input\n",
    "  org_shape = X_test_pooled.shape\n",
    "  X_test_pooled = X_test_pooled.reshape(org_shape[0], org_shape[1], 1)\n",
    "\n",
    "  #model architecture\n",
    "  input_layer = Input(shape = (X_train_pooled_output.shape[1],1))\n",
    "  lstm_layer = CuDNNLSTM(64, return_sequences = True)(input_layer)\n",
    "  flat1 = Flatten()(lstm_layer)\n",
    "  dense = Dense(32,activation = 'relu', kernel_initializer = HeNormal(), kernel_regularizer = L2(0.0001))(flat1)\n",
    "  dropout = Dropout(0.5)(flat1)\n",
    "  output = Dense(2, activation = 'softmax')(dropout)\n",
    "  model = Model(input_layer, output)\n",
    "  #loading the weights of the best model we got\n",
    "  model.load_weights(filepath)\n",
    "  model.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.0006), metrics = [auc])\n",
    "\n",
    "  preds = model.predict(X_test_pooled)\n",
    "  y_pred = preds[:,1]\n",
    "  print(\"No. of datapoints classified as belonging to class 0: \",sum(y_pred<0.5))\n",
    "  print(\"No. of datapoints classified as belonging to class 1: \",sum(y_pred>=0.5))\n",
    "\n",
    "  return (sum(y_pred<0.5), sum(y_pred>=0.5))\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBuaH8inpQDw",
    "outputId": "39e20da6-288e-4f98-af0a-1f41e6990a69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352, 768)\n",
      "No. of datapoints classified as belonging to class 0:  30\n",
      "No. of datapoints classified as belonging to class 1:  322\n"
     ]
    }
   ],
   "source": [
    "no_of_0, no_of_1 = pipeline(test_df, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZc7XTQOxcIO"
   },
   "source": [
    "## Please write your observations at the end of notebook and  explain each and every step you followed in solving this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OnaRBRuMtdjW",
    "outputId": "17454a4a-57ca-40a1-cf1d-f3edf2197da0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-----------+--------+-----------+----------------+\n",
      "|            Features           |   Model   | Epochs | Train AUC | Validation AUC |\n",
      "+-------------------------------+-----------+--------+-----------+----------------+\n",
      "| BERT embeddings for text data | CuDNNLSTM |   28   |   0.9484  |     0.9516     |\n",
      "+-------------------------------+-----------+--------+-----------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Features\", \"Model\", \"Epochs\", \"Train AUC\", \"Validation AUC\"]\n",
    "x.add_row([\"BERT embeddings for text data\", \"CuDNNLSTM\", 28, 0.9484, 0.9516])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBEck1AIuWSD"
   },
   "source": [
    "Observations:\n",
    "\n",
    "1. The difference between train AUC and validation AUC is low. Therefore, there is no overfit/ underfit.\n",
    "\n",
    "2. The use of BERT embeddings enabled us to achieve a good AUC of over 95% in very less epochs even using a simple model with very less no. of trainable parameters in the order of 100,000.\n",
    "\n",
    "3. LSTM is good with capturing patterns. BERT embeddings + a simple LSTM model like the one used here can achieve good results with low computational resuorces in less training time. Hence, NLP with transfer learning is an effective approach. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
